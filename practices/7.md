# ClickHouse特性

本篇记录下ClickHouse与数据库有哪些不同的差异和特性。ClickHouse以下简称为：`CH`

## 概述
`CH`是一款OLAP的列式数据库，并且还是俄罗斯开发的，相比其它OLAP产品具有：

**优势**：
* 存储更海量数据（数亿或万亿）
* 更快的查询速度（1ms-几十ms，看索引及数据颗粒度，每秒高达数十亿行查询能力）
* 更高的数据压缩比（占用空间更小）
* 兼容标准SQL语法
* 原生支持自动聚合数据能力
* 索引占用空间小
* 大批量写入数据（建议一次至少插入 1,000 行的相当大的批次数据，最好在 1W 到 10W 行之间）


**缺点**：
* 较低的QPS（默认100）
* 不支持事务

## 表
`CH`与OLTP关系型数据库一样，拥有`database`、`table`的物理结构以及`主键`、`索引`
```sql
CREATE DATABASE IF NOT EXISTS helloworld;   # 创建库
CREATE TABLE helloworld.my_first_table      # 创建表
(
    user_id UInt32,
    message String,
    timestamp DateTime,
    metric Float32
)
    ENGINE = MergeTree()                    # 使用了MergeTree表引擎
    PARTITION BY toYYYYMM(timestamp)        # 分区
    PRIMARY KEY (user_id, timestamp);       # 主键
```

## 主键
不支持`自增ID`、不具备`唯一标识`特性（只是决定数据的`物理存储顺序`）

没有**主键**时，使用`ORDER BY`的排序健来指定的元组。

主键可以提升查询性能，但过多的主键会对插入性能和内存消耗有负面影响，主键中额外的列并不影响 SELECT 查询的性能。

> 默认情况下，主键与排序键相同（由子句指定ORDER BY）。因此，在大多数情况下，没有必要指定单独的PRIMARY KEY子句。

## 排序健
**主键**和`ORDER BY`同时存在时，**主键**必须是`ORDER BY`的子集，即主键为(a,b)，排序列必须为(a,b,**)

对排序键进行 ALTER 是轻量级的操作

> 排序键可以提高数据的压缩比（极大减少磁盘空间）

## 分区健
每个分区都单独存储，以简化数据的操作。访问数据时，`CH`使用尽可能小的分区子集。

分区不会加速查询，在大多数情况下，您不需要分区键，并且在大多数其他情况下，您不需要比月份更精细的分区键。

分区可用于MergeTree系列表（基于 MergeTree 表的物化视图也支持分区。）

> 分区过多，会导致SELECT由于文件系统中的文件数量和打开的文件描述符数量过多，查询的性能会很差。

## 字段类型
* 字符串
  * `FixedString(N)`：固定长度的字符串，类似数据库的char类型。查询的时候，不足的长度用多个`\0`填补
  * `String`：任意长度的字符串。长度不受限制。取代了 VARCHAR、BLOB、CLOB 以及其他 DBMS 中的其他类型
* 整数类型
  * `UInt8`, `UInt16`, `UInt32`, `UInt64`, `UInt128`, `UInt256`, `Int8`, `Int16`, `Int32`, `Int64`, `Int128`, `Int256`
* 浮点
  * `Float32`,`Float64`
* 十进制
  * `Decimal`, `Decimal(P)`, `Decimal(P, S)`, `Decimal32(S)`, `Decimal64(S)`, `Decimal128(S)`, `Decimal256(S)`
    * P——精度。有效范围：[ 1:76 ] 。确定可以有多少个整数+小数位。默认情况下精度为 10。
    * S——规模。有效范围：[ 0：P ] 。确定可以有多少位小数。
    * `Decimal32(4)` 可以包含从 -99999.9999 到 99999.9999 的数字，步长为 0.0001。
* 布尔值
  * `Bool`：实际使用的是`UInt8`类型
* 唯一标识符 
  * `UUID`：标识记录的 16 字节值，默认00000000-0000-0000-0000-000000000000
    * `generateUUIDv4()` 生成随机UUID
* 日期时间
  * `Date`：支持的值范围：[ 1970-01-01, 2149-06-06 ]
  * `Date32`：比Date支持更长的日期范围
  * `DateTime`：支持的值范围：[ 1970-01-01 00:00:00, 2106-02-07 06:28:15 ] 。
  * `DateTime64`：支持的值范围：[ 1900-01-01 00:00:00, 2299-12-31 23:59:59.99999999 ]
* 枚举
  * `Enum`：自动选择Enum8 or Enum16
  * `Enum8`：支持的值范围：[-128, 127]范围内枚举的 256 个值
  * `Enum16`：支持的值范围：[-32768, 32767]范围内枚举的 65536 个值。
  * 字段定义：fieldName Enum('hello' = 1, 'world' = 2)
* 数组
  * `Array(T)`：类型项的数组T，起始数组索引为 1。T可以是任何数据类型，包括数组。
* 聚合函数
  * `AggregateFunction`：生成聚合函数状态的常见方法是通过调用带有后缀的聚合函数-State。以后要得到聚合的最终结果，必须使用相同的带有-Merge后缀的聚合函数。
  * `SimpleAggregateFunction`：数据类型存储聚合函数的当前值，而不像 AggregateFunction 那样存储其完整状态。
* JSON
  * JSON 数据类型是一项实验性功能。要使用它，请设置allow_experimental_object_type = 1.
* 元组
  * `Tuple(T1, T2, …)`：每个元素都有一个单独的类型。元组必须至少包含一个元素。
* 可空类型
  * `Nullable(类型名)`：例如，Nullable(Int8)类型列可以存储Int8类型值，没有值的行将存储NULL
* IP
  * `IPv4`, `IPv6`
* 地理数据类型
  * `Point`：由其 X 和 Y 坐标表示，存储为元组（Float64、Float64）
  * `Ring`：以点数组形式存储的无孔简单多边形：Array(Point).
  * `Polygon`：是一个带有孔的多边形，存储为环数组：Array ( Ring )
  * `MultiPolygon`：由多个多边形组成，并存储为多边形数组：Array ( Polygon )
* 字典
  * `Map(key, value)`：数据类型存储key:value对

更多信息，查看官方文档：https://clickhouse.com/docs/en/sql-reference/data-types
## 索引
`CH`索引为稀疏索引是通过主键来设置的，非一行记录一条索引的方式。

`CH`的最小数据块是`颗粒（数据块）`，数据被组织成颗粒来处理的并行数据

`颗粒`的设置示例：
```sql
CREATE TABLE hits_UserID_URL
(
    `UserID` UInt32,
    `URL` String,
    `EventTime` DateTime
)
ENGINE = MergeTree
PRIMARY KEY (UserID, URL)
ORDER BY (UserID, URL, EventTime)
SETTINGS index_granularity = 8192, index_granularity_bytes = 0; # 8192行为一个颗粒（数据块）
```

`index_capsularity`    
    
    显式设置为默认值 8192。这意味着对于每组 8192 行，主索引将有一个索引条目，例如，如果表包含 16384 行，则索引将有两个索引条目。
    
`index_grinity_bytes`

    设置为 0 以禁用自适应索引粒度。自适应索引粒度意味着如果满足以下任一条件，ClickHouse 会自动为一组 n 行创建一个索引条目：
    如果 n 小于 8192 并且该 n 行的组合行数据的大小大于或等于 10 MB（index_grainarity_bytes 的默认值）或
    如果 n 行的组合行数据大小小于 10 MB 但 n 为 8192。

索引存储在：一个未压缩的平面数组文件 (primary.idx)，包含从 0 开始的数字索引标记
* 索引标记0：指向颗粒0的第一行列值数据
* 索引标记1：指向颗粒1的第一行的列值数据，依此类推

可以通过打开`EXPLAIN indexes = 1`来查看执行计划：
```sql
EXPLAIN indexes = 1
SELECT URL, count(URL) AS Count
FROM hits_UserID_URL
WHERE UserID = 749927693
GROUP BY URL
ORDER BY Count DESC
LIMIT 10;
```
```sql
┌─explain───────────────────────────────────────────────────────────────────────────────┐
│ Expression (Projection)                                                               │
│   Limit (preliminary LIMIT (without OFFSET))                                          │
│     Sorting (Sorting for ORDER BY)                                                    │
│       Expression (Before ORDER BY)                                                    │
│         Aggregating                                                                   │
│           Expression (Before GROUP BY)                                                │
│             Filter (WHERE)                                                            │
│               SettingQuotaAndLimits (Set limits and quota after reading from storage) │
│                 ReadFromMergeTree                                                     │
│                 Indexes:                                                              │
│                   PrimaryKey                                                          │
│                     Keys:                                                             │
│                       UserID                                                          │
│                     Condition: (UserID in [749927693, 749927693])                     │
│                     Parts: 1/1                                                        │
│                     Granules: 1/1083                                                  │
└───────────────────────────────────────────────────────────────────────────────────────┘

16 rows in set. Elapsed: 0.003 sec.
```
客户端输出显示，**1083** 个颗粒中的**1**被选择为包含 UserID 列值为 749927693 的行。

同样，标记文件也是一个平面未压缩数组文件 (*.mrk)，其中包含从 0 开始编号的标记。每个列均有这么一个mrk文件

`gorm`

    ClickHouse在gorm下使用index的tag标识索引不生效，需要使用order by来设置索引覆盖的字段。
    使用gorm连接clickhouse，默认为：engine=MergeTree，不设置partition by，order by tuple()，并且不会设置cluster。
    在集群上需要设置engine=ReplicatedMergeTree和on cluster deafault_cluster，否则节点之间数据同步出问题

## 表引擎
### MergeTree 引擎系列
    MergeTree 系列的表引擎是 ClickHouse 数据存储功能的核心。它们提供了弹性和高性能数据检索的大部分功能
#### `MergeTree`引擎
    基础MergeTree表引擎可以被视为单节点 ClickHouse 实例的默认表引擎，因为它对于广泛的用例来说是通用且实用的。
#### `ReplacingMergeTree`引擎
    是生产环境的最佳选择，因为它为常规 MergeTree 引擎的添加了高可用性。

    一个好处是自动删除重复数据，因此如果插入过程中出现一些网络问题，软件可以安全地重试。
```sql
CREATE TABLE [IF NOT EXISTS] [db.]table_name [ON CLUSTER cluster]
(
    name1 [type1] [DEFAULT|MATERIALIZED|ALIAS expr1],
    name2 [type2] [DEFAULT|MATERIALIZED|ALIAS expr2],
    ...
) ENGINE = ReplacingMergeTree([ver])
[PARTITION BY expr]
[ORDER BY expr]
[SAMPLE BY expr]
[SETTINGS name=value, ...]
```
    ver — 版本列。类型为 UInt*, Date 或 DateTime。可选参数。
    
    在数据合并的时候，ReplacingMergeTree 从所有具有相同排序键的行中选择一行留下：
    
    如果 ver 列未指定，保留最后一条。
    如果 ver 列已指定，保留 ver 值最大的版本。
#### `AggregatingMergeTree`引擎
    将一个数据片段内所有具有相同主键（准确的说是 排序键）的行聚合成一行，这一行会存储一系列聚合函数的状态。

    引擎使用以下类型来处理所有列：
    AggregateFunction
    SimpleAggregateFunction

例如，创建一个AggregatingMergeTree引擎的物化视图：
```sql
CREATE MATERIALIZED VIEW test.basic
ENGINE = AggregatingMergeTree() PARTITION BY toYYYYMM(StartDate) ORDER BY (CounterID, StartDate)
AS SELECT
    CounterID,
    StartDate,
    sumState(Sign)    AS Visits,
    uniqState(UserID) AS Users
FROM test.visits
GROUP BY CounterID, StartDate;
```
向 test.visits 表中插入数据。
```sql
INSERT INTO test.visits ...
```
数据会同时插入到表和视图中，并且视图 test.basic 会将里面的数据聚合。

要获取聚合数据，我们需要在 test.basic 视图上执行类似 SELECT ... GROUP BY ... 这样的查询 ：
```sql
SELECT
    StartDate,
    sumMerge(Visits) AS Visits,
    uniqMerge(Users) AS Users
FROM test.basic
GROUP BY StartDate
ORDER BY StartDate;
```
#### `SummingMergeTree`引擎
把所有具有相同主键的行合并为一行，该行包含了被合并的行中具有数值数据类型的列的汇总值。

当数据被插入到表中时，他们将被原样保存。

ClickHouse 定期合并插入的数据片段，并在这个时候对所有具有相同主键的行中的列进行汇总，将这些行替换为包含汇总数据的一行记录。
```sql
CREATE TABLE summtt
(
    key UInt32,
    value UInt32
)
ENGINE = SummingMergeTree()
ORDER BY key
```
```sql
INSERT INTO summtt Values(1,1),(1,2),(2,1)
SELECT key, sum(value) FROM summtt GROUP BY key
```
```sql
┌─key─┬─sum(value)─┐
│   2 │          1 │
│   1 │          3 │
└─────┴────────────┘
```
#### `VersionedCollapsingMergeTree`引擎
允许快速写入不断变化的对象状态

当某个对象的状态在不断的发生变化，这时可以使用该引擎来代替Update操作。

该引擎需要额外的两个字段：`Sign`（Int8)、`Version`（Int8)

* Sign：只有两个状态：-1（代表删除）、1（使用的数据）
* Version：数据的版本号（新插入的数据

```sql
CREATE TABLE UAct
(
    UserID UInt64,
    PageViews UInt8,
    Duration UInt8,
    Sign Int8,
    Version UInt8
)
ENGINE = VersionedCollapsingMergeTree(Sign, Version)
ORDER BY UserID

INSERT INTO UAct VALUES (4324182021466249494, 5, 146, 1, 1)
INSERT INTO UAct VALUES (4324182021466249494, 5, 146, -1, 1),(4324182021466249494, 6, 185, 1, 2)
```
```sql
SELECT * FROM UAct
┌──────────────UserID─┬─PageViews─┬─Duration─┬─Sign─┬─Version─┐
│ 4324182021466249494 │         5 │      146 │    1 │       1 │
└─────────────────────┴───────────┴──────────┴──────┴─────────┘
┌──────────────UserID─┬─PageViews─┬─Duration─┬─Sign─┬─Version─┐
│ 4324182021466249494 │         5 │      146 │   -1 │       1 │
│ 4324182021466249494 │         6 │      185 │    1 │       2 │
└─────────────────────┴───────────┴──────────┴──────┴─────────┘
```
由于数据还没有合并，所以查出来的数据仍然是三条，所以可以使用聚合的方式来查询：
```sql
SELECT
    UserID,
    sum(PageViews * Sign) AS PageViews,
    sum(Duration * Sign) AS Duration,
    Version
FROM UAct
GROUP BY UserID, Version
HAVING sum(Sign) > 0

┌──────────────UserID─┬─PageViews─┬─Duration─┬─Version─┐
│ 4324182021466249494 │         6 │      185 │       2 │
└─────────────────────┴───────────┴──────────┴─────────┘
```

#### `CollapsingMergeTree`引擎
与**VersionedCollapsingMergeTree**不同的是，没有`Version`字段。
```sql
CREATE TABLE [IF NOT EXISTS] [db.]table_name [ON CLUSTER cluster]
(
    name1 [type1] [DEFAULT|MATERIALIZED|ALIAS expr1],
    name2 [type2] [DEFAULT|MATERIALIZED|ALIAS expr2],
    ...
) ENGINE = CollapsingMergeTree(sign)
[PARTITION BY expr]
[ORDER BY expr]
[SAMPLE BY expr]
[SETTINGS name=value, ...]
```
第一次插入：
```sql
┌──────────────UserID─┬─PageViews─┬─Duration─┬─Sign─┐
│ 4324182021466249494 │         5 │      146 │    1 │
└─────────────────────┴───────────┴──────────┴──────┘
```
第二次插入两行数据
```sql
┌──────────────UserID─┬─PageViews─┬─Duration─┬─Sign─┐
│ 4324182021466249494 │         5 │      146 │   -1 │
│ 4324182021466249494 │         6 │      185 │    1 │
└─────────────────────┴───────────┴──────────┴──────┘
```
当有两行数据的Sign分别为1、-1，且其它字段完全一样时，这些数据会被合并后自动删除

## 写入
建议批量写入数据
```sql
INSERT INTO helloworld.my_first_table (user_id, message, timestamp, metric) VALUES
    (101, 'Hello, ClickHouse!',                                 now(),       -1.0    ),
    (102, 'Insert a lot of rows per batch',                     yesterday(), 1.41421 ),
    (102, 'Sort your data based on your commonly-used queries', today(),     2.718   ),
    (101, 'Granules are the smallest chunks of data read',      now() + 5,   3.14159 )
```
> 插入ClikHouse需要判断数据进入哪个partition和order，尽量使一段时间内的插入最终归到一个partition，例如按天，PARTITION BY toYYYYMMDD(XXXX) order by time

## 查询
> `CH`默认查询QPS最高为`100`

配置文件调整：查看 ClickHouse 的配置文件（通常是config.xml），找到以下参数并进行相应的调整：

    max_connections：增加最大连接数的限制，允许更多的并发连接。将其值适当增加，以满足并发查询的需求。
    max_concurrent_queries：增加最大并发查询数的限制。将其值适当增加，以允许更多的并发查询同时执行。
    max_threads：增加线程池中线程的数量，以增加并发处理能力。

## 更新
无法更新属于主键或排序键的列。

    对于不经常更改的数据，对数据进行版本控制可能是更好的选择。
    ClickHouse 是存储效率和查询性能方面排名第一的分析数据库，因此在许多情况下仅保存多个版本的数据而不是更新可能会效果更好。

更新不带WHERE条件的办法：
```sql
ALTER TABLE table
    UPDATE col1 = 'bye' WHERE true
```
## 删除
轻量级删除（仅适用于 MergeTree 表引擎系列）
```sql
DELETE FROM hits WHERE Title LIKE '%hello%';
```
删除的行会立即标记为已删除状态，后续查询是将自动过滤掉，因此您不必等待各部分的合并或使用关键字FINAL。数据清理在后台异步发生。

删除整表：
```sql
TRUNCATE TABLE [<database].]<table>
```
## 物化视图
物化视图是一种自动将源数据聚合到目标表的能力

所以通常来说在物化视图会有三张“表”：数据源表、物化视图、目标表
```sql
# 用于物化视图存储数据的表（目标表）
CREATE TABLE analytics.monthly_aggregated_data
(
    `domain_name` String,
    `month` Date,
    `sumCountViews` AggregateFunction(sum, UInt64)
)
ENGINE = AggregatingMergeTree
ORDER BY (domain_name, month)

# 创建物化视图以及TO后面的目标表
CREATE MATERIALIZED VIEW analytics.monthly_aggregated_data_mv
TO analytics.monthly_aggregated_data
AS
SELECT
    toDate(toStartOfMonth(event_time)) AS month,
    domain_name,
    sumState(count_views) AS sumCountViews
FROM analytics.hourly_data
GROUP BY
    domain_name,
    month
```
当数据源表`analytics.hourly_data`有数据insert into时，数据会被自动聚合到`analytics.monthly_aggregated_data`表

这就是`物化视图`的作用。可以让我们少写很多代码。特别适合需要数据聚合的报表上。

## 手动备份
```shell
# 暂停Clickhouse写入
SYSTEM STOP DISTRIBUTED SENDS;

# 手动cp
cp -r /var/lib/clickhouse/* /path/to/backup/directory/

# 备份元数据
clickhouse-metastore --backup --path /path/to/backup/directory/

# 恢复Clickhouse写入
SYSTEM START DISTRIBUTED SENDS;
```

## 手动还原
```shell
# 暂停Clickhouse写入
systemctl stop clickhouse-server

# 手动cp
cp -r /path/to/backup/directory/* /var/lib/clickhouse/

# 备份元数据
clickhouse-metastore --restore --path /path/to/backup/directory/

# 恢复Clickhouse写入
systemctl start clickhouse-server
```

## docker安装运行
我这里把`CH`的日志、配置、数据文件，放到了/home/nfs/clickhouse目录，根据你的实际情况来修改。
```shell
# 创建目录
mkdir -p /home/nfs/clickhouse/data /home/nfs/clickhouse/log

# 运行一个临时容器（为了拷贝配置出来）
rm -rf /home/nfs/clickhouse/config
docker run -d --rm --name tmp_ch --ulimit nofile=262144:262144 \
clickhouse/clickhouse-server

# 复制临时容器的配置到本地
docker cp tmp_ch:/etc/clickhouse-server/ /home/nfs/clickhouse/
mv /home/nfs/clickhouse/clickhouse-server /home/nfs/clickhouse/config
docker kill tmp_ch

# 新建一个root用户，密码为123456，并允许192.168.1.0 - 192.168.1.255的内网访问，你可以直接改成：::/0 允许全部
cat <<EOF | sudo tee /home/nfs/clickhouse/config/users.d/root.xml
<clickhouse>
  <timezone>Asia/Istanbul</timezone>
    <profiles>
        <root>
        </root>
    </profiles>
    <users>
        <root>
            <password>123456</password>
            <networks>
                <ip>192.168.1.0/24</ip>
            </networks>
            <profile>root</profile>
            <quota>root</quota>
        </root>
    </users>
    <quotas>
        <root>
            <interval>
                <duration>3600</duration>
                <queries>0</queries>
                <errors>0</errors>
                <result_rows>0</result_rows>
                <read_rows>0</read_rows>
                <execution_time>0</execution_time>
            </interval>
        </root>
    </quotas>
</clickhouse>
EOF

# 正式运行容器
docker run -d --name ch --network host --ulimit nofile=262144:262144 \
-v /home/nfs/clickhouse/data:/var/lib/clickhouse \
-v /home/nfs/clickhouse/log:/var/log/clickhouse-server \
-v /home/nfs/clickhouse/config:/etc/clickhouse-server \
--restart=always \
clickhouse/clickhouse-server
```